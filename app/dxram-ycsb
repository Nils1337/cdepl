#
# Copyright (C) 2018 Heinrich-Heine-Universitaet Duesseldorf, Institute of Computer Science, Department Operating Systems
#
# This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>
#

#!/bin/bash

readonly __DXRAM_YCSB_BINARY="bin/dxram"

readonly __DXRAM_YCSB_LOG_FILE_SUPERPEER_POSTFIX="_superpeer"
readonly __DXRAM_YCSB_LOG_FILE_STORE_POSTFIX="_store"
readonly __DXRAM_YCSB_LOG_FILE_BENCH_POSTFIX="_bench"

readonly __DXRAM_YCSB_MAIN_CLASS="de.hhu.bsinfo.dxram.DXRAM"
readonly __DXRAM_YCSB_CLASS_PATH="lib/*"

readonly __DXRAM_YCSB_DEFAULT_S_PORT="22221"
readonly __DXRAM_YCSB_DEFAULT_PS_PORT="22222"
readonly __DXRAM_YCSB_DEFAULT_PB_PORT="22223"

readonly __DXRAM_YCSB_PROCESS_IDENTIFIER="dxramdeployscript"
readonly __DXRAM_YCSB_DEFAULT_STARTUP_CONDITION="!---ooo---!"
readonly __DXRAM_YCSB_RUN_OR_LOAD_DONE_CONDITION="!---YCSB---!"

readonly __DXRAM_YCSB_REQUIRED_ENVIRONMENT="java/1.8 gcc/6.1"

__DXRAM_YCSB_PATH=""
__DXRAM_YCSB_CONFIG_PATH=""
__DXRAM_YCSB_LOG4J_CONFIG_PATH=""

__DXRAM_YCSB_OUT_PATH=""
__DXRAM_YCSB_OUT_CONF_PATH=""
__DXRAM_YCSB_OUT_LOG_PATH=""

__DXRAM_YCSB_CACHED_NODES_CONFIG=""

__DXRAM_YCSB_ZOOKEEPER_NODE=""
__DXRAM_YCSB_ZOOKEEPER_PORT=""

__DXRAM_YCSB_NODE_TYPE=()
__DXRAM_YCSB_NODE_PORT=()
__DXRAM_YCSB_NODE_NETWORK=()
__DXRAM_YCSB_NODE_MSG_HANDLER=()
__DXRAM_YCSB_NODE_PEER_KVSS=()

__DXRAM_YCSB_NODE_RUN_SUDO=()
__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT=()
__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT=()
__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB=()

__DXRAM_YCSB_TOTAL_STORAGE_NODES=""
__DXRAM_YCSB_TOTAL_BENCHMARK_NODES=""

__DXRAM_YCSB_NODE_THREADS=()

# Specify workload inline
__DXRAM_YCSB_WORKLOAD_RECORDCOUNT=""
__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT=""
__DXRAM_YCSB_WORKLOAD_READPROPORTION=""
__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION=""
__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION=""
__DXRAM_YCSB_WORKLOAD_FIELDCOUNT=""
__DXRAM_YCSB_WORKLOAD_FIELDLENGTH=""

__DXRAM_YCSB_NODE_INSERTSTART=()

##
# Initialize and setup the DXRAM YCSB environment. This must be called before any
# other function of the dxram-ycsb module.
#
# $1 path Path to folder containing build output of ycsb-dxram with bin, config
#    folder etc
# $2 zookeeper_node Node running the zookeeper server necessary to bootstrap
#    DXRAM
# $3 zookeeper_port Port of the zookeper server running on the specified node
##
cdepl_app_dxram_ycsb_init()
{
	local path=$1
	local zookeeper_node=$2
	local zookeeper_port=$3

	__DXRAM_YCSB_PATH="$(cdepl_cluster_node_cmd 0 "readlink -f $path")"
	__DXRAM_YCSB_CONFIG_PATH="${__DXRAM_YCSB_PATH}/config/dxram.json"
	__DXRAM_YCSB_LOG4J_CONFIG_PATH="${__DXRAM_YCSB_PATH}/config/log4j2.xml"

	__DXRAM_YCSB_OUT_PATH="${__DEPLOY_CUR_OUT_PATH}/dxram_ycsb"
	__DXRAM_YCSB_OUT_CONF_PATH="${__DXRAM_YCSB_OUT_PATH}/conf"
	__DXRAM_YCSB_OUT_LOG_PATH="${__DXRAM_YCSB_OUT_PATH}/log"

	__DXRAM_YCSB_ZOOKEEPER_NODE="$zookeeper_node"
	__DXRAM_YCSB_ZOOKEEPER_PORT="$zookeeper_port"

	# Check if dxram ycsb path is available
	if [ ! "$__DXRAM_YCSB_PATH" ] || [ "$(cdepl_cluster_file_system_cmd "[ -d $__DXRAM_YCSB_PATH ] && echo \"1\"")" != "1" ]; then
		util_log_error_and_exit "[dxram-ycsb]: Path does not exist ($path), resolved path: $__DXRAM_YCSB_PATH"
	fi

	__cdepl_app_dxram_ycsb_check
	__cdepl_app_dxram_ycsb_check_config

	# Output path setup
	cdepl_cluster_file_system_cmd "mkdir -p $__DXRAM_YCSB_OUT_CONF_PATH"
	cdepl_cluster_file_system_cmd "mkdir -p $__DXRAM_YCSB_OUT_LOG_PATH"

	util_log "[dxram-ycsb] Initialized: $__DXRAM_YCSB_PATH"
	util_log "[dxram-ycsb] Output: $__DXRAM_YCSB_OUT_PATH"
}

# in order to declare a node an actual DXRAM node, you have to assign a role
# no default role, node will be ignored and not considered a dxram node

##
# Set the node type for a DXRAM YCSB instance running on a node.
#
# In order to declare a node an actual DXRAM node/instance, you have yo assign
# a role. There is no default node role applied, otherwise. The node will be
# ignored and not considered a DXRAM node/instance.
#
# $1 node Node to set the DXRAM YCSB role for
# $2 type DXRAM YCSB node type to set for the specified node: S (superpeer), 
#    PS (peer storage) or PB (peer benchmark)
##
cdepl_app_dxram_ycsb_node_type()
{
	local node=$1
	local type=$2

	# No default values. If node type not set explicitly, node is not considered to run a DXRAM YCSB instance
	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	# Superpeer (S), peer store (PS) or peer bench (PB)
	if [ "$type" != "S" ] && [ "$type" != "PS" ] && [ "$type" != "PB" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node type $type for node $node"
	fi

	__DXRAM_YCSB_NODE_TYPE[$node]="$type"
}

##
# Set the port for a node running a DXRAM YCSB instance
#
# $1 node Node of the DXRAM YCSB instance
# $2 port Port (ethernet) to set
##
cdepl_app_dxram_ycsb_node_port()
{
	local node=$1
	local port=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$port" -gt "65536" ] || [ "$port" -lt "0" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid port $port for node $node"
	fi

	__DXRAM_YCSB_NODE_PORT[$node]="$port"
}

##
# Set the network type of DXRAM YCSB instance on the target node
#
# $1 node Node of the DXRAM YCSB instance
# $2 network Network type to set (eth, ib)
##
cdepl_app_dxram_ycsb_node_network()
{
	local node=$1
	local network=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$network" != "eth" ] && [ "$network" != "ib" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid network type $network for node $node"
	fi

	__DXRAM_YCSB_NODE_NETWORK[$node]="$network"
}

##
# Set the number of message handlers for the network subsystem to use for the
# DXRAM YCSB instance running on the target node
#
# $1 node Node of the DXRAM YCSB instance
# $2 msg_handler Number of message handlers to use on the specified node
##
cdepl_app_dxram_ycsb_node_message_handler()
{
	local node=$1
	local msg_handler=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_MSG_HANDLER[$node]="$msg_handler"
}

##
# Set the key-value store size (in MB) for the target DXRAM YCSB instance. The
# instance must be declared as a PS (peer storage)
#
# $1 node Node of the DXRAM YCSB instance
# $2 kvss Key-value storage size in MB
##
cdepl_app_dxram_ycsb_peer_kvss()
{
	local node=$1
	local kvss=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_PEER_KVSS[$node]="$kvss"
}

##
# Run the DXRAM YCSB instance with sudo on the target node (e.g. might be necessary
# if using InfiniBand networking)
#
# $1 node Node of the DXRAM YCSB instance
##
cdepl_app_dxram_ycsb_run_as_sudo()
{
	local node=$1

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$(cdepl_cluster_allows_sudo)" ]; then
		__DXRAM_YCSB_NODE_RUN_SUDO[$node]="1"
	else
		util_log_warn "[$node][dxram-ycsb] Cluster type does not allow running commands as sudo, ignored"
	fi
}

##
# Run the DXRAM YCSB instance with parameters to enable remote debugging. Once
# enabled, a string with information how to attach the debugger will be printed
# on deployment
#
# $1 node Node of the DXRAM YCSB instance
# $2 port Port to assign to the debugger to use
##
cdepl_app_dxram_ycsb_remote_debug()
{
	local node=$1
	local port=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]="$port"
}

##
# Run the DXRAM YCSB instance with parameters to enable profiling with the Yourkit
# profiler. A string with information how to attach the debugger will be printed
# on deployment
#
# $1 node Node of the DXRAM YCSB instance
# $2 port Port for the remote profiler
# $3 agent_lib Path on the target node with the libyjpagent.so lib
##
cdepl_app_dxram_ycsb_remote_profile_yjp()
{
	local node=$1
	local port=$2
	local agent_lib=$3

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	# Check if the agent lib is available
	if [ "$(cdepl_cluster_node_cmd $node "[ -f $agent_lib ] && echo \"1\"")" != "1" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Could not find libyjpagent.so in $agent_lib"
	fi

	__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]="$port"
	__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB[$node]="$agent_lib"
}

##
# Set the total number of storage nodes for the YCSB benchmark
#
# #1 total_nodes Total number of storages nodes
##
cdepl_app_dxram_ycsb_total_storage_nodes()
{
	local total_nodes=$1

	__DXRAM_YCSB_TOTAL_STORAGE_NODES="$total_nodes"
}

##
# Set the total number of benchmark nodes for the YCSB benchmark
#
# #1 total_nodes Total number of benchmark nodes
##
cdepl_app_dxram_ycsb_total_benchmark_nodes()
{
	local total_nodes=$1

	__DXRAM_YCSB_TOTAL_BENCHMARK_NODES="$total_nodes"
}

##
# Set the number of ycsb threads to run on a benchmark node
#
# $1 node Target benchmark node
# $2 threads Number of threads to start on the target benchmark node
##
cdepl_app_dxram_ycsb_threads()
{
	local node=$1
	local threads=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_THREADS[$node]="$threads"
}

# specify inline workload instead of using workload config making the deploy
# script more self containing
##
# Specify an inline workload instead of using a workload config making the
# deployment script more self containing
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
# $3 readportion Distribution of reads
# $4 updateportion Distribution of updates
# $5 requestdistribution Distribution of requests (zipfian, uniform)
# $6 fieldcount Number of fields per object
# $7 fieldlength Length of a single field
##
cdepl_app_dxram_ycsb_workload()
{
	local recordcount=$1
	local operationcount=$2
	local readportion=$3
	local updateportion=$4
	local requestdistribution=$5
	local fieldcount=$6
	local fieldlength=$7

	__DXRAM_YCSB_WORKLOAD_RECORDCOUNT="$recordcount"
	__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT="$operationcount"
	__DXRAM_YCSB_WORKLOAD_READPROPORTION="$readportion"
	__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION="$updateportion"
	__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION="$requestdistribution"
	__DXRAM_YCSB_WORKLOAD_FIELDCOUNT="$fieldcount"
	__DXRAM_YCSB_WORKLOAD_FIELDLENGTH="$fieldlength"
}

##
# Set the insert start offset when creating/inserting objects during loading
#
# $1 node Target storage node
# $2 insertstart Insert start offset for chunk IDs
##
cdepl_app_dxram_ycsb_insertstart()
{
	local node=$1
	local insertstart=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_INSERTSTART[$node]="$insertstart"
}

##
# Wrapper to set workload a
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
##
cdepl_app_dxram_ycsb_workload_a()
{
	local recordcount=$1
	local operationcount=$2

	cdepl_app_dxram_ycsb_workload $recordcount $operationcount "0.5" "0.5" "zipfian" "10" "100"
}

##
# Wrapper to set workload b
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
##
cdepl_app_dxram_ycsb_workload_b()
{
	local recordcount=$1
	local operationcount=$2

	cdepl_app_dxram_ycsb_workload $recordcount $operationcount "0.95" "0.05" "zipfian" "10" "100"
}

##
# Wrapper to set workload g
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
##
cdepl_app_dxram_ycsb_workload_g()
{
	local recordcount=$1
	local operationcount=$2

	cdepl_app_dxram_ycsb_workload $recordcount $operationcount "0.5" "0.5" "zipfian" "1" "64"
}

##
##
# Start a DXRAM YCSB instance on the target node.
#
# $1 node_range_start Node id to start instance on (or range start)
# $2 node_range_end (optional) If specified, all nodes from the range start to
#    end are started
##
cdepl_app_ycsb_dxram_start_node()
{
	local node_range_start=$1
	local node_range_end=$2

	# We have to resolve these values once, only.
	# Same as creating the cached nodes config to speed things up
	if [ ! "$__DXRAM_YCSB_CACHED_NODES_CONFIG" ]; then
		__cdepl_app_dxram_ycsb_resolve_default_config_values
	fi

	if [ "$node_range_end" ]; then
		# If the initial cache isn't filled, create cache for first node
		# then run everything else in parallel
		if [ ! "$__DXRAM_YCSB_CACHED_NODES_CONFIG" ]; then
			__cdepl_app_dxram_ycsb_create_node_base_config $node_range_start
		fi

		local pids=""

		for node in $(seq $node_range_start $node_range_end); do
			__cdepl_app_ycsb_dxram_start_node $node &
			pids="$pids $!"
		done

		wait $pids
	else
		__cdepl_app_ycsb_dxram_start_node $node_range_start
	fi
}

##
# Wait for a started DXRAM YCSB instance to be started. A DXRAM YCSB instance is
# considered started once all components and services are initialized
# (signaled by a specific string to be printed).
#
# $1 node Target node id with started DXRAM YCSB instance
##
cdepl_app_dxram_ycsb_node_wait_superpeer_started()
{
	local node=$1

	local type="${__DXRAM_YCSB_NODE_TYPE[$node]}"
	local logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_SUPERPEER_POSTFIX}

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" != "S" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$type] Waiting for node to be started, not a superpeer"
	fi

	util_log "[$node][dxram-ycsb][$type] Waiting for startup"

	while true; do
		echo -n "."

		local success=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep '$__DXRAM_YCSB_DEFAULT_STARTUP_CONDITION'")
		local fail_init=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep '^Initializing DXRAM failed.$'")
		# Abort execution after an exception was thrown (every exception but NetworkResponseCancelledException)
		local fail_error=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i 'exception' | grep -v 'NetworkResponseCancelledException' | grep -v 'fpu_exception'")
		# "A fatal error" -> JVM segfaults
		local fail_error2=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i -e '\[ERROR\]' -e '\# A fatal error'")

		if [ "$success" ]; then
			local pid=$(__cdepl_app_dxram_ycsb_get_instance_running_pid $node ${__DXRAM_YCSB_NODE_PORT[$node]})

			echo ""

			if [ ! "$pid" ]; then
				util_log_error_and_exit "[$node][dxram-ycsb][$type] Could not find started process"
			fi

			util_log "[$node][dxram-ycsb][$type] Started (pid: $pid)"

			break
		elif [ "$fail_init" ]; then
			echo ""
			util_log_error_and_exit "[$node][dxram-ycsb][$type] Could not be started. See log file $logfile"
			return 1
		elif [ "$fail_error" ] || [ "$fail_error2" ]; then
			echo ""
			util_log_error_and_exit "[$node][dxram-ycsb][$type] Failed, error or exception. See log file $logfile"
			return 2
		fi

		sleep 1.0
	done

	return 0
}

##
# Check for a YCSB storage instance if it finished loading
#
# $1 node Node id of a strange node to check
# $2 hide_progress (optional) Set to 1 to hide output of the loading progress
##
cdepl_app_dxram_ycsb_storage_finished_loading()
{
	local node=$1
	local hide_progress=$2

	local type="${__DXRAM_YCSB_NODE_TYPE[$node]}"
	local logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_STORE_POSTFIX}

	if [ "$type" != "PS" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$type] Invalid node type $type to wait for load storage finish"
	fi

	util_log "[$node][dxram-ycsb][$type] Waiting for storage loading to finish: $__DXRAM_YCSB_RUN_OR_LOAD_DONE_CONDITION"

	local first_progress=1

	while true; do
		if [ ! "$hide_progress" ]; then
			local progress=$(cdepl_cluster_node_cmd $node "cat $logfile | grep 'current ops' | tail -n 1")

			if [ ! "$progress" ]; then
				echo -n "."
			else
				if [ "$first_progress" = "1" ]; then
					first_progress=0
					echo ""
				fi

				echo "[$node] ${progress}"
			fi
		else
			echo -n "."
		fi

		local success=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep '$__DXRAM_YCSB_RUN_OR_LOAD_DONE_CONDITION'")
		# Abort execution after an exception was thrown (every exception but NetworkResponseCancelledException)
		local fail_error=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i 'exception' | grep -v 'NetworkResponseCancelledException' | grep -v 'fpu_exception'")
		# "A fatal error" -> JVM segfaults
		local fail_error2=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i -e '\[ERROR\]' -e '\# A fatal error'")

		if [ "$fail_error" ] || [ "$fail_error2" ]; then
			echo ""
			err=""
			
			if [ "$fail_error" ]; then
				err="$fail_error"
			else
				err="$fail_error2"
			fi

			util_log_error_and_exit "[$node][dxram-ycsb][$type] Failed, error or exception:\n${err}\nSee log file $logfile"
		fi

		if [ "$success" ]; then
			echo ""
			util_log "[$node][dxram-ycsb][$type] Storage loading complete"
			break;
		fi

		sleep 1.0
	done

	return 0
}

##
# Check for a YCSB benchmark instance if it running the benchmark
#
# $1 node Node id of a benchmark node to check
# $2 hide_progress (optional) Set to 1 to hide output of the benchmark progress
##
cdepl_app_dxram_ycsb_benchmark_wait_finished()
{
	local node=$1
	local hide_progress=$2

	local type="${__DXRAM_YCSB_NODE_TYPE[$node]}"
	local logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_BENCH_POSTFIX}

	if [ "$type" != "PB" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$type] Invalid node type $type to wait for benchmark to finish"
	fi

	util_log "[$node][dxram-ycsb][$type] Waiting for benchmark to finish: $__DXRAM_YCSB_RUN_OR_LOAD_DONE_CONDITION"

	local first_progress=1

	while true; do
		if [ ! "$hide_progress" ]; then
			local progress=$(cdepl_cluster_node_cmd $node "cat $logfile | grep 'current ops' | tail -n 1")

			if [ ! "$progress" ]; then
				echo -n "."
			else
				if [ "$first_progress" = "1" ]; then
					first_progress=0
					echo ""
				fi

				echo "[$node] ${progress}"
			fi
		else
			echo -n "."
		fi

		local success=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep '$__DXRAM_YCSB_RUN_OR_LOAD_DONE_CONDITION'")
		# Abort execution after an exception was thrown (every exception but NetworkResponseCancelledException)
		local fail_error=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i 'exception' | grep -v 'NetworkResponseCancelledException' | grep -v 'fpu_exception'")
		# "A fatal error" -> JVM segfaults
		local fail_error2=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i -e '\[ERROR\]' -e '\# A fatal error'")

		if [ "$fail_error" ] || [ "$fail_error2" ]; then
			echo ""
			err=""
			
			if [ "$fail_error" ]; then
				err="$fail_error"
			else
				err="$fail_error2"
			fi

			util_log_error_and_exit "[$node][dxram-ycsb][$type] Failed, error or exception:\n${err}\nSee log file $logfile"
		fi

		if [ "$success" ]; then
			echo ""
			util_log "[$node][dxram-ycsb][$type] Benchmark completed"
			break;
		fi

		sleep 1.0
	done

	return 0
}

##
# Cleanup any still running or remaining/crashed instances on the target node
#
# $1 Target node id (or start node id of range if second parameter provided)
# $2 Optional: Node id range end (including) and first parameter is interpreted
#    as range start (including)
##
cdepl_app_dxram_ycsb_node_cleanup()
{
	local node_range_start=$1
	local node_range_end=$2

	if [ "$node_range_end" ]; then
		local pids=""

		for node in $(seq $node_range_start $node_range_end); do
			__cdepl_app_dxram_ycsb_cleanup $node &
			pids="$pids $!"
		done

		wait $pids
	else
		__cdepl_app_dxram_ycsb_cleanup $node_range_start
	fi
}

#################################################

__cdepl_app_dxram_ycsb_check()
{
	if [ "$(cdepl_cluster_node_cmd 0 "[ -f ${__DXRAM_YCSB_PATH}/bin/ycsb ] && echo 1")" != "1" ]; then
		util_log_error_and_exit "[0][dxram-ycsb] Could not find bin/ycsb in $__DXRAM_YCSB_PATH"
	fi
}

__cdepl_app_dxram_ycsb_check_config()
{
	# Check if config file is available and create default config
	if [ "$(cdepl_cluster_node_cmd 0 "[ -f $__DXRAM_YCSB_CONFIG_PATH ] && echo \"1\"")" != "1" ]; then
		util_log "[0][dxram-ycsb] No config file available, creating default config: $__DXRAM_YCSB_CONFIG_PATH"

		# Don't run this on the login node (might not have java installed)
		# Use the first actual cluster node instead
		# sync: Ensure everything's written to disk and visible for other nodes
		cdepl_cluster_node_cmd 0 "cd $__DXRAM_YCSB_PATH && DXRAM_OPTS='-Dlog4j.configurationFile=$__DXRAM_YCSB_LOG4J_CONFIG_PATH -Ddxram.config=$__DXRAM_CONFIG_PATH' ./$__DXRAM_YCSB_BINARY > /dev/null 2>&1" "$__DXRAM_YCSB_REQUIRED_ENVIRONMENT"

		# Sanity check
		if [ "$(cdepl_cluster_node_cmd 0 "[ -f $__DXRAM_YCSB_CONFIG_PATH ] && echo \"1\"")" != "1" ]; then
			util_log_error_and_exit "[0][dxram-ycsb] Creating config file $__DXRAM_YCSB_CONFIG_PATH failed"
		fi
	else
		local config_content="$(cdepl_cluster_node_cmd 0 "cat "$__DXRAM_YCSB_CONFIG_PATH"")"
		# Check if corrupted configuration file
		local component_header=`echo $config_content | grep "m_componentConfigs"`
		local service_header=`echo $config_content | grep "m_serviceConfigs"`
		if [ "$component_header" = "" ] && [ "$service_header" = "" ] ; then
			util_log "[0][dxram-ycsb] Configuration file $__DXRAM_YCSB_CONFIG_PATH corrupted, deleting and creating default"

			# Configuration file seems to be corrupted -> start dxram once to create new configuration
			cdepl_cluster_node_cmd 0 "rm $__DXRAM_YCSB_CONFIG_PATH && cd $__DXRAM_YCSB_PATH && DXRAM_OPTS='-Dlog4j.configurationFile=$__DXRAM_YCSB_LOG4J_CONFIG_PATH -Ddxram.config=$__DXRAM_CONFIG_PATH' ./$__DXRAM_YCSB_BINARY > /dev/null 2>&1" "$__DXRAM_YCSB_REQUIRED_ENVIRONMENT"

			# Sanity check
			if [ "$(cdepl_cluster_node_cmd 0 "[ -f $__DXRAM_YCSB_CONFIG_PATH ] && echo \"1\"")" != "1" ]; then
				util_log_error_and_exit "[0][dxram-ycsb] Creating config file $__DXRAM_YCSB_CONFIG_PATH failed"
			fi
		fi
	fi
}

__cdepl_app_dxram_ycsb_resolve_default_config_values()
{
	local node_count="$(cdepl_cluster_get_alloc_node_count)"

	for i in `seq 0 $((node_count - 1))`; do
		# Only for explicitly set node types = DXRAM instance
		if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "S" ] && [ "${__DXRAM_YCSB_NODE_PORT[$i]}" = "" ]; then
			__DXRAM_YCSB_NODE_PORT[$i]="$__DXRAM_YCSB_DEFAULT_S_PORT"
		fi

		if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "PS" ] && [ "${__DXRAM_YCSB_NODE_PORT[$i]}" = "" ]; then
			__DXRAM_YCSB_NODE_PORT[$i]="$__DXRAM_YCSB_DEFAULT_PS_PORT"
		fi

		if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "PB" ] && [ "${__DXRAM_YCSB_NODE_PORT[$i]}" = "" ]; then
			__DXRAM_YCSB_NODE_PORT[$i]="$__DXRAM_YCSB_DEFAULT_PB_PORT"
		fi
	done
}

__cdepl_app_dxram_ycsb_create_node_base_config()
{
	local node=$1

	local node_config_path="${__DXRAM_YCSB_OUT_CONF_PATH}/node_${node}.conf"
	local tmp_file="$(cdepl_deploy_get_local_tmp_path)/tmp_dxram_ycsb_${node}.conf"

	# Create base node config once and cache it
	if [ ! "$__DXRAM_YCSB_CACHED_NODES_CONFIG" ]; then
		local zookeeper_ip="$(cdepl_cluster_resolve_node_to_ip $__DXRAM_YCSB_ZOOKEEPER_NODE)"
		cdepl_cluster_download_from_remote $__DXRAM_YCSB_CONFIG_PATH $tmp_file
		local node_config=$(cat $tmp_file)

		if [ zookeeper_ip = "" ]; then
			util_log_error_and_exit "[$node][dxram-ycsb] Could not resolve zookeeper ip for node $__DXRAM_YCSB_ZOOKEEPER_NODE"
		fi

		# Insert zookeeper config values
		# Create replacement string for zookeeper configuration
		local zookeeper_config_string="
			\"m_path\": \"/dxram\",
			\"m_connection\": {
				\"m_ip\": \"$zookeeper_ip\",
				\"m_port\": $__DXRAM_YCSB_ZOOKEEPER_PORT
			},"

		# Replace zookeeper configuration
		local current_node_config="$(echo "$node_config" | sed '/ZookeeperBootComponentConfig/q')"
		current_node_config="${current_node_config}${zookeeper_config_string}"
		local end="$(echo "$node_config" | sed -ne '/ZookeeperBootComponentConfig/{s///; :a' -e 'n;p;ba' -e '}')"
		end="$(echo "$end" | sed -ne '/},/{s///; :a' -e 'n;p;ba' -e '}')"
		current_node_config="$(echo -e "${current_node_config}\n${end}")"

		node_config="$current_node_config"

		# Insert node config mappings
		# Create replacement string for nodes configuration:
		local default_node="{
			\"m_address\": {
				\"m_ip\": \"IP_TEMPLATE\",
				\"m_port\": PORT_TEMPLATE
			},
			\"m_role\": \"ROLE_TEMPLATE\",
			\"m_rack\": 0,
			\"m_switch\": 0,
			\"m_readFromFile\": 1
		}"

		local node_config_string=""
		local first_iterartion=true

		# Create "List" of node configs for configuration file
		for i in `seq 0 $(($(cdepl_cluster_get_alloc_node_count) - 1))`; do
			local ip=""
			local port=""
			local role=""

			ip="$(cdepl_cluster_resolve_node_to_ip "$i")"

			if [ ! "ip" ]; then
				util_log_error_and_exit "[$node][dxram-ycsb] Could not resolve node to ip"
			fi

			port="${__DXRAM_YCSB_NODE_PORT[$i]}"

				# Only for explicitly set node types = DXRAM instance
			if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "S" ]; then
				role="SUPERPEER"
			elif [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "PS" ] || [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "PB" ]; then
				role="PEER"
			fi

			if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" ]; then
				local node_string=`echo "$default_node" | sed "s/IP_TEMPLATE/$ip/" | sed "s/PORT_TEMPLATE/$port/" | sed "s/ROLE_TEMPLATE/$role/"`

				# Separate items of list with ,
				if [ "$first_iterartion" == true ]; then
					node_config_string="${node_config_string}${node_string}"
					first_iterartion=false
				else
					node_config_string="${node_config_string},${node_string}"
				fi
			fi
		done

		# Close node config list
		node_config_string="$(echo -e "$node_config_string\n      ],")"

		# Replace nodes configuration:
		local new_config="$(echo "${node_config}" | sed '/m_nodesConfig/q')"
		new_config="${new_config}${node_config_string}"
		local end="$(echo "${node_config}" | sed -ne '/m_nodesConfig/{s///; :a' -e 'n;p;ba' -e '}')"
		end="$(echo "${end}" | sed -ne '/],/{s///; :a' -e 'n;p;ba' -e '}')"
		new_config="$(echo -e "${new_config}\n${end}")"
	else
		local new_config="$__DXRAM_YCSB_CACHED_NODES_CONFIG"
	fi

	echo "$new_config" > $tmp_file

	# Write back new config
	cdepl_cluster_upload_to_remote $tmp_file $node_config_path
}

__cdepl_app_ycsb_dxram_start_node()
{
	local node=$1

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] No node type set, cannot start instance"
	fi

	local logfile=""

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "S" ]; then
		logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_SUPERPEER_POSTFIX}
	elif [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "PS" ]; then
		logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_STORE_POSTFIX}
	elif [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "PB" ]; then
		logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_BENCH_POSTFIX}
	else
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node type ${__DXRAM_YCSB_NODE_TYPE[$node]} cannot start instance"
	fi

	
	__cdepl_app_dxram_ycsb_create_node_base_config $node

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "S" ]; then
		__cdepl_app_dxram_ycsb_start_superpeer $node $logfile
	elif [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "PS" ]; then
		__cdepl_app_dxram_ycsb_start_peer $node "load" $logfile
	elif [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "PB" ]; then
		__cdepl_app_dxram_ycsb_start_peer $node "run" $logfile
	fi
}


__cdepl_app_dxram_ycsb_start_superpeer()
{
	local node=$1
	local logfile=$2

	local node_config_path="${__DXRAM_YCSB_OUT_CONF_PATH}/node_${node}.conf"

	util_log "[$node][dxram-ycsb][S] Starting superpeer, logfile: $logfile config: $node_config_path"

	local ip="$(cdepl_cluster_resolve_hostname_to_ip "$(cdepl_cluster_node_resolve_node_to_hostname $node)")"

	if [ ! "$ip" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][S] Could not resolve hostname '$(cdepl_cluster_node_resolve_node_to_hostname $node)' to ip"
	fi

	local vm_opts=""

	# Required to fix JNI crashing with libIbdxnet (see JNINotes.md in ibnet repository)
	vm_opts="-XX:+UseMembar"

	vm_opts="$vm_opts -Dlog4j.configurationFile=$__DXRAM_YCSB_LOG4J_CONFIG_PATH"
	vm_opts="$vm_opts -Ddxram.config=$node_config_path"
	vm_opts="$vm_opts -Ddxram.m_config.m_engineConfig.m_address.m_ip=$ip"
	vm_opts="$vm_opts -Ddxram.m_config.m_engineConfig.m_address.m_port=${__DXRAM_YCSB_NODE_PORT[$node]}"
	vm_opts="$vm_opts -Ddxram.m_config.m_engineConfig.m_role=Superpeer"

	# Optional dxram node specific settings

	if [ "${__DXRAM_YCSB_NODE_NETWORK[$node]}" = "eth" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[NetworkComponentConfig].m_core.m_device=Ethernet"
	elif [ "${__DXRAM_YCSB_NODE_NETWORK[$node]}" = "ib" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[NetworkComponentConfig].m_core.m_device=Infiniband"
	fi

	if [ "${__DXRAM_YCSB_NODE_MSG_HANDLER[$node]}" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[NetworkComponentConfig].m_core.m_numMessageHandlerThreads=${DXRAM_NODE_MSG_HANDLER[$node]}"
	fi

	# Development and debugging

	local root=""
	if [ "${__DXRAM_YCSB_NODE_RUN_SUDO[$node]}" = "1" ]; then
		util_log "[$node][dxram-ycsb][S] Running with sudo"
		root="sudo -E -P"
	fi

	if [ "${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}" != "" ]; then
		vm_opts="$vm_opts -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
		util_log "[$node][dxram-ycsb][S] Enabled remote debugging on port ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
		util_log "[$node][dxram-ycsb][S] On your local machine: establish a tunnel using 'ssh <target_hostname> -L ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}:<target_hostname>:${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}' and connect your debugger to localhost, port ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
	fi

	if [ "${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}" != "" ]; then
		vm_opts="$vm_opts -agentpath:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB[$node]}=port=${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}"

		util_log "[$node][dxram-ycsb][S] On your local machine: establish a tunnel using 'ssh <target_hostname> -L ${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}:<target_hostname>:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}' and connect with yourkit using 'Connect to remote application' with the arguments 'localhost:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}'"
	fi

	vm_opts="$vm_opts -D${__DXRAM_YCSB_PROCESS_IDENTIFIER}"

	# Don't use && instead of ;
	# This will hang if ssh with controlmaster and nohup is used
	cdepl_cluster_node_cmd $node "cd $__DXRAM_YCSB_PATH ; JAVA_OPTS='$vm_opts' $root nohup ./$__DXRAM_YCSB_BINARY > $logfile 2>&1 &" "$__DXRAM_YCSB_REQUIRED_ENVIRONMENT"
}

__cdepl_app_dxram_ycsb_start_peer()
{
	local node=$1
	local ycsb_type=$2
	local logfile=$3

	local node_config_path="${__DXRAM_YCSB_OUT_CONF_PATH}/node_${node}.conf"

	util_log "[$node][dxram-ycsb][$ycsb_type] Starting $ycsb_type peer, logfile: $logfile config: $node_config_path"

	local ip="$(cdepl_cluster_resolve_hostname_to_ip "$(cdepl_cluster_node_resolve_node_to_hostname $node)")"

	if [ ! "$ip" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$ycsb_type] Could not resolve hostname '$(cdepl_cluster_node_resolve_node_to_hostname $node)' to ip"
	fi

	local zookeeper_ip="$(cdepl_cluster_resolve_node_to_ip $__DXRAM_YCSB_ZOOKEEPER_NODE)"

	if [ zookeeper_ip = "" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$ycsb_type] Could not resolve zookeeper ip for node $__DXRAM_YCSB_ZOOKEEPER_NODE"
	fi

	local vm_opts=""
	local ycsb_params=""

	# Required to fix JNI crashing with libIbdxnet (see JNINotes.md in ibnet repository)
	vm_opts="-XX:+UseMembar"

	vm_opts="$vm_opts -Dlog4j.configurationFile=$__DXRAM_YCSB_LOG4J_CONFIG_PATH"
	vm_opts="$vm_opts -Ddxram.config=$node_config_path"
	vm_opts="$vm_opts -Ddxram.m_config.m_engineConfig.m_address.m_ip=$ip"
	vm_opts="$vm_opts -Ddxram.m_config.m_engineConfig.m_address.m_port=${__DXRAM_YCSB_NODE_PORT[$node]}"
	vm_opts="$vm_opts -Ddxram.m_config.m_engineConfig.m_role=Peer"

	# Optional dxram node specific settings

	if [ "${__DXRAM_YCSB_NODE_NETWORK[$node]}" = "eth" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[NetworkComponentConfig].m_core.m_device=Ethernet"
	elif [ "${__DXRAM_YCSB_NODE_NETWORK[$node]}" = "ib" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[NetworkComponentConfig].m_core.m_device=Infiniband"
	fi

	if [ "${__DXRAM_YCSB_NODE_MSG_HANDLER[$node]}" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[NetworkComponentConfig].m_core.m_numMessageHandlerThreads=${__DXRAM_YCSB_NODE_MSG_HANDLER[$node]}"
	fi

	if [ "${__DXRAM_YCSB_NODE_PEER_KVSS[$node]}" ]; then
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[MemoryManagerComponentConfig].m_keyValueStoreSize.m_value=${__DXRAM_YCSB_NODE_PEER_KVSS[$node]}"
		vm_opts="$vm_opts -Ddxram.m_config.m_componentConfigs[MemoryManagerComponentConfig].m_keyValueStoreSize.m_unit=mb"
	fi

	# Development and debugging

	local root=""
	if [ "${__DXRAM_YCSB_NODE_RUN_SUDO[$node]}" = "1" ]; then
		util_log "[$node][dxram-ycsb][$ycsb_type] Running with sudo"
		root="sudo -E -P"
	fi

	if [ "${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}" != "" ]; then
		vm_opts="$vm_opts -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
		util_log "[$node][dxram-ycsb][$ycsb_type] Enabled remote debugging on port ${DXRAM_NODE_REMOTE_DEBUG_PORT[$node]}"
		util_log "[$node][dxram-ycsb][$ycsb_type] On your local machine: establish a tunnel using 'ssh <target_hostname> -L ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}:<target_hostname>:${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}' and connect your debugger to localhost, port ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
	fi

	if [ "${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}" != "" ]; then
		vm_opts="$vm_opts -agentpath:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB[$node]}=port=${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}"

		util_log "[$node][dxram-ydxb][$ycsb_type] On your local machine: establish a tunnel using 'ssh <target_hostname> -L ${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}:<target_hostname>:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}' and connect with yourkit using 'Connect to remote application' with the arguments 'localhost:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}'"
	fi

	vm_opts="$vm_opts -D${__DXRAM_YCSB_PROCESS_IDENTIFIER}"

	# YCSB settings

	ycsb_params="$ycsb_params -p zookeeper.string=${zookeeper_ip}:${__DXRAM_YCSB_ZOOKEEPER_PORT}"
	ycsb_params="$ycsb_params -p status.interval=1"

	if [ ! "$__DXRAM_YCSB_TOTAL_STORAGE_NODES" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$ycsb_type] Cannot run DXRAM client without total storage nodes parameter specified"
	fi

	ycsb_params="$ycsb_params -p dxram.nodes_store=$__DXRAM_YCSB_TOTAL_STORAGE_NODES"

	if [ ! "$__DXRAM_YCSB_TOTAL_BENCHMARK_NODES" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$ycsb_type] Cannot run DXRAM client without total benchmark nodes parameter specified"
	fi

	ycsb_params="$ycsb_params -p dxram.nodes_run=$__DXRAM_YCSB_TOTAL_BENCHMARK_NODES"

	if [ ! "${__DXRAM_YCSB_NODE_THREADS[$node]}" ] || [ "$ycsb_type" = "load" ]; then
		# Auto default to single thread
		# And limit to single threaded on storage load nodes
		__DXRAM_YCSB_NODE_THREADS[$node]="1"
	fi

	if [ ! "${__DXRAM_YCSB_NODE_INSERTSTART[$node]}" ] && [ "$ycsb_type" = "load" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb][$ycsb_type] Missing value for insertstart parameter for storage"
	fi

	if [ "${__DXRAM_YCSB_NODE_INSERTSTART[$node]}" ]; then
		ycsb_params="$ycsb_params -p insertstart=${__DXRAM_YCSB_NODE_INSERTSTART[$node]}"
	fi

	# Force ordered because hashing is not supported by dxram
	ycsb_params="$ycsb_params -p insertorder=ordered"
	ycsb_params="$ycsb_params -p readallfields=true"
	ycsb_params="$ycsb_params -p scanproportion=0.0"
	ycsb_params="$ycsb_params -p updateproportion=0.0"

	if [ "$__DXRAM_YCSB_WORKLOAD_RECORDCOUNT" ]; then
		ycsb_params="$ycsb_params -p recordcount=$__DXRAM_YCSB_WORKLOAD_RECORDCOUNT"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT" ]; then
		ycsb_params="$ycsb_params -p operationcount=$__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_READPROPORTION" ]; then
		ycsb_params="$ycsb_params -p readproportion=$__DXRAM_YCSB_WORKLOAD_READPROPORTION"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION" ]; then
		ycsb_params="$ycsb_params -p updateproportion=$__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION" ]; then
		ycsb_params="$ycsb_params -p requestdistribution=$__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_FIELDCOUNT" ]; then
		ycsb_params="$ycsb_params -p fieldcount=$__DXRAM_YCSB_WORKLOAD_FIELDCOUNT"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_FIELDLENGTH" ]; then
		ycsb_params="$ycsb_params -p fieldlength=$__DXRAM_YCSB_WORKLOAD_FIELDLENGTH"
	fi

	# Assuming the ycsb and dxram folders are merged

	# Use workloada as default if no further parameters are overwriting the default workload
	# JVM options must be specified using the JAVA_OPTS env var

	# Don't use && instead of ;
	# This will hang if ssh with controlmaster and nohup is used
	cdepl_cluster_node_cmd $node "cd $__DXRAM_YCSB_PATH ; $root nohup ./bin/ycsb $ycsb_type dxram -jvm-args '$vm_opts' -threads ${__DXRAM_YCSB_NODE_THREADS[$node]} -s -P workloads/workloada $ycsb_params > $logfile 2>&1 &"
}

__cdepl_app_dxram_ycsb_get_instance_running_pid()
{
	local node=$1
	local port=$2

	if [ "$port" ]; then
		port=".*-Ddxram.m_config.m_engineConfig.m_address.m_port=${port}"
	fi

	# Consider port for multiple instances on a single machine (e.g. localhost)
	echo "$(cdepl_cluster_node_cmd $node "pgrep -f '^java${port}.*-D${__DXRAM_YCSB_PROCESS_IDENTIFIER}'")"
}

__cdepl_app_dxram_ycsb_cleanup()
{
	local node=$1

	util_log "[$node][dxram-ycsb] Cleanup..."

	local pid=$(__cdepl_app_dxram_ycsb_get_instance_running_pid $node)

	if [ "$pid" ]; then
		# If we or someone else left some garbage processes on the node multiple
		# pids are returned
		for i in $pid; do
			local kill_out=$(cdepl_cluster_node_cmd $node "kill -9 $i 2>&1")

			if [ "$?" = "0" ] && [ ! "$kill_out" ]; then
				util_log "[$node][dxram-ycsb] Killed (pid: $i)"
			elif [ "$kill_out" ]; then
				# Probably operation not permitted, try root
				cdepl_cluster_node_cmd $node "sudo -P kill -9 $i > /dev/null 2>&1"

				if [ "$?" = "0" ]; then
					util_log "[$node][dxram-ycsb] Killed (root) (pid: $i)"
				elif [ "$?" != "1" ]; then
					util_log_warn "[$node][dxram-ycsb] Killing (root) $i failed, DXRAM YCSB instance(s) might stay alive"
				fi
			elif [ "$?" != "1" ]; then
				util_log_warn "[$node][dxram-ycsb] Killing $i failed, DXRAM YCSB instance(s) might stay alive"
			fi
		done
	fi
}
